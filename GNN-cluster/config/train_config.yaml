# config/train_config.yaml
job_name: "Test_07"

model:
  name: "RGCNModel"         # Choices: GCNModel, GATModel, RGCNModel
  in_channels: 384          # Dimension of node embeddings (e.g., node2vec: 64, sbert: 384)
  hidden_channels: 64
  out_channels: 1          # Forever 1; Unused when output_embedding is True
  num_layers: 3            # Only counts hidden layers; input/output layers are built-in; At least 2 for GCNModel
  reduced_qn_dim: 64        # For RGCNModel
  reduced_node_dim: 64      # For RGCNModel
  PROC_QN_EMBED_DIM: 4     # For GCNModel only
  PROC_X_DIM: 4            # For GCNModel only
  num_heads: 8             # GAT-specific
  output_embedding: True   # If true, outputs node embeddings
  use_residuals: True       # If true, residual connections will be added

train:
  batch_size: 64                   # Number of samples processed before model updates (16, 32, 64, 128)
  num_epochs: 100                    # Total number of passes through the training dataset
  learning_rate: 0.001            # Step size for updating model weights during training
  start_idx: 0                     # Starting index for dataset slicing (e.g., for training subsets)
  end_idx: 2000                       # Ending index for dataset slicing (e.g., for training subsets)
  patience: 5                      # Number of epochs with no improvement before early stopping
  equal_subgraph_weighting: True   # When True, each subgraph is weighted equally regardless of size
  hits_at_k: 3                     # Top-k hits to consider for the hits@k metric during evaluation

  contrastive_loss_type: "LearnableMargin"
  # Choices:
  # - "default": Allows larger batch sizes
  # - "margin": Allows larger batch sizes
  # - "MNRL": Requires smaller batch sizes
  # - "LearnableMargin"
  # (If any other option is specified, "default" will be used automatically)

  margin: 0.5                      # For margin type contrastive loss only (0.2, 0.3, 0.4, 0.5)
  temperature: 0.05                # For MNRL type contrastive loss only

val:
  start_idx: 50000                 # Starting index for dataset slicing (e.g., for validation subsets)
  end_idx: 50200                   # Ending index for dataset slicing (e.g., for validation subsets)

test:
  start_idx: 0                     # Starting index for dataset slicing (e.g., for testing subsets)
  end_idx: 200                       # Ending index for dataset slicing (e.g., for testing subsets)

node_embed: "../data/embeddings/ud_node2vec_embeddings.txt"  # Path to node embeddings file
idxes: "../data/data_preparation/idxes.json"  # Path to indexes file
train_qa_data: "../data/raw/2-hop/qa_train.txt"  # Path to QA dataset
test_qa_data: "../data/raw/2-hop/qa_test.txt"
raw_kb: "../data/raw/kb.txt"  # Path to full KB (for constructing subgraphs from paths extracted) -- NEW
num_hops: 2  # Number of hops for dataset configuration

threshold_model_activate: False  # Forever false; Wraps GNN with threshold model if true
threshold_value: 0.5            # Threshold value used when threshold model is inactive

from_paths_activate: False  # Constructs subgraphs from paths extracted -- NEW
entity_sbert: True          # When True, use SBERT instead of node2vec for node embeddings
