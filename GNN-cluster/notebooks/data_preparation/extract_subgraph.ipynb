{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import k_hop_subgraph\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create PyTorch Geometric Data object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_object(edge_index, relations, entity_to_idx):\n",
    "    unique_relations = list(set(relations))\n",
    "    relation_mapping = {relation: index for index, relation in enumerate(unique_relations)}\n",
    "\n",
    "    edge_index = torch.tensor(edge_index).t().contiguous()\n",
    "    # Make the graph undirected by adding reverse edges\n",
    "    undirected_edge_index = torch.cat([edge_index, edge_index.flip(0)], dim=1) # comment out if want directed\n",
    "    edge_attr = torch.tensor([relation_mapping[rel] for rel in relations])\n",
    "    # Since we now have more edges (two for each undirected edge), we concat them\n",
    "    undirected_edge_attr = torch.cat([edge_attr, edge_attr], dim=0) # comment out if want directed\n",
    "\n",
    "    return Data(edge_index=undirected_edge_index, edge_attr=undirected_edge_attr, num_nodes=len(entity_to_idx))\n",
    "\n",
    "def load_data_json(filename='../Datasets/MetaQA_dataset/processed/idxes.json'):\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data['entity_to_idx'], data['edge_index'], data['relations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 267164], edge_attr=[267164], num_nodes=43234)\n"
     ]
    }
   ],
   "source": [
    "loaded_entity_to_idx, loaded_edge_index, loaded_relations = load_data_json() \n",
    "data = create_data_object(loaded_edge_index, loaded_relations, loaded_entity_to_idx)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert QA entities and answers to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_qa_entities_and_answers(file_path):\n",
    "    extracted_entities = []\n",
    "    extracted_answers = []\n",
    "    \n",
    "    with open(file_path, 'r') as file:\n",
    "        for line_number, line in enumerate(file, start=1):  \n",
    "            # Split the line into question and answers\n",
    "            parts = line.strip().split('\\t')\n",
    "            if len(parts) < 2:\n",
    "                print(f\"Line {line_number}: Not enough parts found.\")\n",
    "                continue\n",
    "            \n",
    "            question, answers = parts[0], parts[1]\n",
    "            \n",
    "            # Use regex to find entities in []\n",
    "            matches = re.findall(r'\\[(.*?)\\]', question)\n",
    "            if not matches:\n",
    "                print(f\"Line {line_number}: No entities found.\")\n",
    "            else:\n",
    "                extracted_entities.extend(matches)\n",
    "                \n",
    "            # Extract answers by splitting the answers string on '|'\n",
    "            answer_list = answers.split('|')\n",
    "            extracted_answers.append(answer_list)\n",
    "\n",
    "    return extracted_entities, extracted_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_file = '../Datasets/MetaQA_dataset/vanilla 3-hop/qa_train.txt'\n",
    "qa_entities, qa_answers = extract_qa_entities_and_answers(qa_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert extracted entities to indices\n",
    "qa_entity_indices = [loaded_entity_to_idx[entity] for entity in qa_entities if entity in loaded_entity_to_idx]\n",
    "\n",
    "# Convert extracted answers to indices\n",
    "qa_answer_indices = [[loaded_entity_to_idx[ans] for ans in answer_list if ans in loaded_entity_to_idx] for answer_list in qa_answers]\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "qa_entity_tensor = torch.tensor(qa_entity_indices, dtype=torch.long)\n",
    "qa_answer_tensor = [torch.tensor(answer_indices, dtype=torch.long) for answer_indices in qa_answer_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract subgraphs \n",
    "(3 hops from each QA entity of interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the k-hop subgraph\n",
    "def get_khop_subgraph(data, entity_index, k):\n",
    "    subset, sub_edge_index, mapping, edge_mask = k_hop_subgraph(\n",
    "        node_idx=entity_index,\n",
    "        num_hops=k,\n",
    "        edge_index=data.edge_index\n",
    "    )\n",
    "    return subset, sub_edge_index, mapping, edge_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsets = []\n",
    "\n",
    "for entity_index in qa_entity_indices:\n",
    "    subset, _, _, _ = get_khop_subgraph(data, entity_index, 3)\n",
    "    subsets.append(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(subsets, '../Datasets/MetaQA_dataset/processed/qa_train_subsets.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsets = torch.load('../Datasets/MetaQA_dataset/processed/qa_train_subsets.pt', weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25475"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subsets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114196"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subsets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
