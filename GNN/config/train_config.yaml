# config/train_config.yaml
model:
  name: "GCNModel"
  in_channels: 64
  hidden_channels: 256 # Specify the number of hidden units here
  out_channels: 64
  num_heads: 8
  num_layers: 3 # Specify the number of layers here
  question_embedding_dim: 384

train:
  batch_size: 128
  num_epochs: 100
  learning_rate: 0.001
  start_idx: 0
  end_idx: 2500
  equal_subgraph_weight: True
  do_masking: False

val:
  start_idx: 0
  end_idx: 500
  batch_size: 16

test:
  start_idx: 0
  end_idx: 500
  batch_size: 16

node_embed: "data/embeddings/ud_node2vec_embeddings.txt" # Path to node embeddings file
idxes: "data/processed/idxes.json" # Path to indexes file
train_qa_data: "data/raw/qa_train.txt" # Path to QA dataset
val_qa_data: "data/raw/qa_dev.txt"
test_qa_data: "data/raw/qa_test.txt"
train_ans_types: "data/raw/qa_train_qtype.txt"
val_ans_types: "data/raw/qa_dev_qtype.txt"
test_ans_types: "data/raw/qa_test_qtype.txt"

num_hops: 3 # Number of hops for dataset configuration
save_dir: "checkpoints"
sentence_transformer_path: "src/models/models--sentence-transformers--multi-qa-MiniLM-L6-cos-v1/snapshots/2d981ed0b0b8591b038d472b10c38b96016aab2e"
