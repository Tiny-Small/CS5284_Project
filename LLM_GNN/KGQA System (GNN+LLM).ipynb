{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4edfd7c9",
   "metadata": {},
   "source": [
    "## Environment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2cbf596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/svu/e0315913/.local/lib/python3.8/site-packages')\n",
    "sys.path.append('/home/svu/e0315913/.local/bin')\n",
    "sys.path.append(\"/hpctmp/e0315913/demo/CS5284_Project/GNN-cluster/config/demo_config.yaml\")\n",
    "\n",
    "import os\n",
    "os.chdir('/hpctmp/e0315913/demo/CS5284_Project/GNN-cluster/')\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s', force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098c7ec7",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59c8c1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa2e4e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.config import load_config, validate_config\n",
    "from src.utils.evaluation import evaluate\n",
    "from src.models.alpha import FullOutput, Metrics, threshold_based_candidates, calculate_avg_metrics\n",
    "from src.models.rgcn_model import RGCNModel\n",
    "from src.models.alpha import Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ca79a2",
   "metadata": {},
   "source": [
    "Set config and device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6c3b15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATH = \"config/demo_config.yaml\"\n",
    "\n",
    "config = load_config(CONFIG_PATH)\n",
    "required_keys = [\n",
    "    'model','train', 'node_embed', 'idxes',\n",
    "    'train_qa_data', 'test_qa_data', 'num_hops',\n",
    "]\n",
    "validate_config(config, required_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4bdf9fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(2024)\n",
    "random.seed(2024)\n",
    "np.random.seed(2024)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62e447d",
   "metadata": {},
   "source": [
    "## Load Encoding Model (multi-qa-MiniLM-L6-cos-v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "070f89d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import json, random, torch\n",
    "import pandas as pd\n",
    "\n",
    "from torch_geometric.utils import k_hop_subgraph, subgraph\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "from torch_geometric.data import Data\n",
    "import networkx as nx\n",
    "\n",
    "from sentence_transformers import util, SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13914f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-20 10:12:18,536 - INFO - Use pytorch device_name: cuda\n",
      "2024-11-20 10:12:18,537 - INFO - Load pretrained SentenceTransformer: /hpctmp/e0315913/CS5284_Project/GNN-cluster/src/models/models--sentence-transformers--multi-qa-MiniLM-L6-cos-v1/snapshots/2d981ed0b0b8591b038d472b10c38b96016aab2e\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SentenceTransformer(\"/hpctmp/e0315913/CS5284_Project/GNN-cluster/src/models/models--sentence-transformers--multi-qa-MiniLM-L6-cos-v1/snapshots/2d981ed0b0b8591b038d472b10c38b96016aab2e\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dcf5b3",
   "metadata": {},
   "source": [
    "## KGQADataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b656609",
   "metadata": {},
   "source": [
    "KGQADataset has been modified to return actual paths (not embeddings) and candidate node values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a35bdb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KGQADataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, path_to_node_embed, path_to_idxes, path_to_qa, path_to_kb, from_paths_activate, entity_sbert, k=3):\n",
    "        self.from_paths_activate = from_paths_activate\n",
    "        self.entity_sbert = entity_sbert\n",
    "\n",
    "        if self.from_paths_activate:\n",
    "            self.G = self.generate_nx_graph(path_to_kb)\n",
    "        self.loaded_entity_to_idx, self.loaded_edge_index, self.loaded_relations = self.load_data_json(path_to_idxes)\n",
    "        self.data = self.create_data_object(self.loaded_edge_index, self.loaded_relations, self.loaded_entity_to_idx)\n",
    "        self.num_relations = len(set(self.loaded_relations))\n",
    "        self.k = k\n",
    "        self.entity_sbert_embeddings = self.get_entity_sbert_embeddings(self.loaded_entity_to_idx)\n",
    "        self.node2vec_embeddings = self.load_node2vec_embeddings(path_to_node_embed)\n",
    "        self.df = pd.read_csv(path_to_qa, sep='\\t', header=None, names=['question', 'answer'])\n",
    "        self.df['answer'] = self.df['answer'].apply(lambda x: x.split(\"|\"))\n",
    "        self.q_embeddings = model.encode(\n",
    "            [q.replace(\"[\", \"\").replace(\"]\", \"\") for q in self.df['question']],\n",
    "            batch_size=128,\n",
    "            convert_to_tensor=True\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        question, answers = row['question'], row['answer']\n",
    "        entity = self.extract_entity_from_question(question)\n",
    "        entity_node = self.loaded_entity_to_idx[entity]\n",
    "        question_embedding = self.q_embeddings[idx]\n",
    "        subset_node_indices, sub_edge_index, _, edge_mask = self.get_k_hop_subgraph(entity_node)\n",
    "        subgraph_data, node_map = self.construct_subgraph(subset_node_indices, sub_edge_index, edge_mask)\n",
    "        labels = self.get_labels(answers, node_map)\n",
    "        embedding_dim = 384 if (self.from_paths_activate or self.entity_sbert) else 64\n",
    "        subgraph_data.x = self.get_node_embeddings(node_map, question_embedding, entity, embedding_dim)\n",
    "\n",
    "        actual_paths = []\n",
    "        if self.from_paths_activate:\n",
    "            paths = self.find_paths(self.G, entity, 2) + self.find_paths(self.G, entity, 1)\n",
    "            for path in paths:\n",
    "                actual_paths.append([(node, relation) for node, relation in path])\n",
    "\n",
    "        return subgraph_data, question_embedding, labels, node_map, actual_paths\n",
    "\n",
    "    def get_entity_sbert_embeddings(self, loaded_entity_to_idx):\n",
    "        entities = list(loaded_entity_to_idx.keys())\n",
    "        encoded_values = model.encode(entities, batch_size=128, convert_to_tensor=False).tolist()\n",
    "        out = {e: encoded_values[i] for i, e in enumerate(entities)}\n",
    "        return out\n",
    "\n",
    "    def get_k_hop_subgraph(self, entity_node):\n",
    "        subset, sub_edge_index, mapping, edge_mask = k_hop_subgraph(\n",
    "            node_idx=entity_node,\n",
    "            num_hops=self.k,\n",
    "            edge_index=self.data.edge_index,\n",
    "            relabel_nodes=True\n",
    "        )\n",
    "        return subset, sub_edge_index, mapping, edge_mask\n",
    "\n",
    "    def construct_subgraph(self, subset_node_indices, sub_edge_index, edge_mask):\n",
    "        node_map = {old_idx.item(): new_idx for new_idx, old_idx in enumerate(subset_node_indices)}\n",
    "        sub_edge_attr = self.data.edge_attr[edge_mask]\n",
    "        subgraph_data = Data(edge_index=sub_edge_index, edge_attr=sub_edge_attr) # sub_edge_index is get_k_hop_subgraph's sub_edge_index\n",
    "        return subgraph_data, node_map\n",
    "\n",
    "    def load_data_json(self, filename):\n",
    "        with open(filename, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        return data['entity_to_idx'], data['edge_index'], data['relations']\n",
    "\n",
    "    def load_data_pt(self, filename):\n",
    "        data = torch.load(filename)\n",
    "        if isinstance(data, list):\n",
    "            return data \n",
    "        else:\n",
    "            raise ValueError(\"Expected a list of k-hop subgraph node indices.\")\n",
    "\n",
    "    def create_data_object(self, edge_index, relations, entity_to_idx):\n",
    "        unique_relations = list(set(relations))\n",
    "        relation_mapping = {relation: index for index, relation in enumerate(unique_relations)}\n",
    "\n",
    "        edge_index = torch.tensor(edge_index).t().contiguous()\n",
    "        undirected_edge_index = torch.cat([edge_index, edge_index.flip(0)], dim=1) \n",
    "        edge_attr = torch.tensor([relation_mapping[rel] for rel in relations])\n",
    "        undirected_edge_attr = torch.cat([edge_attr, edge_attr], dim=0)\n",
    "        return Data(edge_index=undirected_edge_index, edge_attr=undirected_edge_attr, num_nodes=len(entity_to_idx))\n",
    "\n",
    "    def load_node2vec_embeddings(self, file_path, embedding_dim=64):\n",
    "        embeddings_dict = {}\n",
    "        with open(file_path, 'r') as f:\n",
    "            next(f)\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                entity = \" \".join(parts[:-embedding_dim]) \n",
    "                embedding = list(map(float, parts[-embedding_dim:])) \n",
    "                embeddings_dict[entity] = embedding\n",
    "\n",
    "        return embeddings_dict\n",
    "\n",
    "    def extract_entity_from_question(self, question):\n",
    "        start = question.find('[') + 1\n",
    "        end = question.find(']')\n",
    "        if start == 0 or end == -1:\n",
    "            raise ValueError(f\"No entity found in the question: {question}\")\n",
    "        return question[start:end]\n",
    "\n",
    "    def get_labels(self, answers, node_map):\n",
    "        labels = torch.zeros(len(node_map), dtype=torch.long)\n",
    "        for ans in answers:\n",
    "            if ans in self.loaded_entity_to_idx:\n",
    "                ans_idx = self.loaded_entity_to_idx[ans]\n",
    "                if ans_idx in node_map:\n",
    "                    labels[node_map[ans_idx]] = 1\n",
    "        return labels\n",
    "\n",
    "    def get_node_embeddings(self, node_map, question_embedding, entity, embedding_dim, random_init=False):\n",
    "        embeddings = [np.zeros(embedding_dim).tolist() for _ in range(len(node_map))]\n",
    "        idx_to_entity = {v: k for k, v in self.loaded_entity_to_idx.items()}  # Reverse map\n",
    "\n",
    "        if self.from_paths_activate:\n",
    "            result = self.find_best_embedding(self.G, entity, question_embedding)\n",
    "            result[entity] = question_embedding \n",
    "\n",
    "        for ori, new in node_map.items():\n",
    "            if random_init:\n",
    "                embeddings[new] = [random.uniform(-0.1, 0.1) for _ in range(embedding_dim)]\n",
    "            elif ori in idx_to_entity and idx_to_entity[ori] in self.node2vec_embeddings:\n",
    "                if self.entity_sbert:\n",
    "                    embeddings[new] = self.entity_sbert_embeddings[idx_to_entity[ori]]\n",
    "                elif self.from_paths_activate:\n",
    "                    embeddings[new] = result[idx_to_entity[ori]].tolist()\n",
    "                else:\n",
    "                    embeddings[new] = self.node2vec_embeddings[idx_to_entity[ori]]\n",
    "\n",
    "        embeddings = np.array(embeddings)\n",
    "        if embeddings.ndim != 2:\n",
    "            raise ValueError(f\"Embeddings array must be 2D but got {embeddings.ndim}D\")\n",
    "\n",
    "        return torch.tensor(embeddings, dtype=torch.float)\n",
    "\n",
    "    def generate_nx_graph(self, path):\n",
    "        df = pd.read_csv(path, sep='|', header=None, names=['entity1', 'relation', 'entity2'])\n",
    "        df_unique = df.drop_duplicates() # 133582 edges after dedup\n",
    "        reverse_relations = {\n",
    "        'directed_by': 'directed',\n",
    "        'written_by': 'written',\n",
    "        'starred_actors': 'starring',\n",
    "        'has_tags': 'is_tagged_to',\n",
    "        'has_genre': 'is_genre_of',\n",
    "        'has_imdb_rating': 'is_imdb_rating_of',\n",
    "        'has_imdb_votes': 'is_imdb_votes_of',\n",
    "        'in_language': 'language_of',\n",
    "        'release_year': 'is_released_year_of'\n",
    "        }\n",
    "\n",
    "        reverse_rows = []\n",
    "        for index, row in df_unique.iterrows():\n",
    "            reverse_relation = reverse_relations[row['relation']]\n",
    "            reverse_row = {'entity1': row['entity2'], 'relation': reverse_relation, 'entity2': row['entity1']}\n",
    "            reverse_rows.append(reverse_row)\n",
    "\n",
    "        df_reverse = pd.DataFrame(reverse_rows) # 133582 edges\n",
    "        df_combined = pd.concat([df_unique, df_reverse], ignore_index=True) # 267164 edges\n",
    "\n",
    "        df_final = df_combined.groupby(['entity1', 'entity2'], as_index=False).agg({\n",
    "            'relation': ' and '.join\n",
    "        }) # 249349 edges\n",
    "        df_final['relation'] = df_final['relation'].str.replace('_', ' ')\n",
    "        G = nx.from_pandas_edgelist(df_final, source='entity1', target='entity2', edge_attr='relation', create_using=nx.DiGraph())\n",
    "        return G\n",
    "\n",
    "    def find_paths(self, G, u, n):\n",
    "\n",
    "        if n == 0:\n",
    "            return [[(u, None)]]\n",
    "\n",
    "        paths = [\n",
    "            [(u, G[u][neighbor]['relation'])] + path\n",
    "            for neighbor in G.neighbors(u)\n",
    "            for path in self.find_paths(G, neighbor, n - 1)\n",
    "            if u not in [node for node, _ in path] # Avoid cycles\n",
    "        ]\n",
    "        return paths\n",
    "\n",
    "    def find_best_embedding(self, G, query_entity, q_embedding):\n",
    "\n",
    "        paths = self.find_paths(G, query_entity, 2) + self.find_paths(G, query_entity, 1)\n",
    "\n",
    "        sentences = []\n",
    "        candidates = []\n",
    "\n",
    "        for tuple_list in paths:\n",
    "            # Extract the last entity (candidate) in the path\n",
    "            candidate_entity = tuple_list[-1][0]\n",
    "\n",
    "            if candidate_entity != query_entity: # Avoid looping back to the query_entity\n",
    "                candidates.append(candidate_entity)\n",
    "                # Create the sentence for the path\n",
    "                sentence = ' '.join(f\"{tup[0]} {tup[1]}\" if tup[1] else tup[0] for tup in tuple_list)\n",
    "                sentences.append(sentence)\n",
    "\n",
    "        path_embeddings = model.encode(sentences, batch_size=128, convert_to_tensor=True)\n",
    "        cosine_scores = util.cos_sim(q_embedding, path_embeddings)[0]\n",
    "        best_embeddings = {}\n",
    "        best_scores = {}\n",
    "\n",
    "        for idx, candidate in enumerate(candidates):\n",
    "            cosine_score = cosine_scores[idx].item()\n",
    "\n",
    "            if candidate not in best_embeddings or cosine_score > best_scores[candidate]:\n",
    "                best_scores[candidate] = cosine_score\n",
    "                best_embeddings[candidate] = path_embeddings[idx]\n",
    "\n",
    "        return best_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "165edbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Batch\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    DataLoader expects each batch to contain tensors or arrays, but torch_geometric.data.Data objects need to be batched in a special way.\n",
    "    \"\"\"\n",
    "    subgraphs, question_embeddings, labels, node_maps, path = zip(*batch)\n",
    "\n",
    "    # Batch the subgraphs\n",
    "    batched_subgraphs = Batch.from_data_list(subgraphs)\n",
    "\n",
    "    # Stack the question embeddings and labels\n",
    "    question_embeddings = torch.stack(question_embeddings)\n",
    "\n",
    "    # Concatenate labels and reshape to (N, 1) where N is the total number of nodes in the batch\n",
    "    stacked_labels = torch.cat(labels).unsqueeze(1)\n",
    "\n",
    "    return batched_subgraphs, question_embeddings, stacked_labels, node_maps, list(labels), list(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f998f536",
   "metadata": {},
   "source": [
    "# Extraction Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facbdae2",
   "metadata": {},
   "source": [
    "The function extractes candidate nodes from GNN and paths of the candidate node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8854c316",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_candidate_nodes_and_paths(dataloader, model, device, threshold_value, train_dataset):\n",
    "    model.eval()\n",
    "\n",
    "    # Initialize lists to store processed data\n",
    "    all_paths = []  # List to store paths of high similarity nodes\n",
    "    all_candidate_values = []  # List to store candidate node values\n",
    "\n",
    "    reversed_index = {value: key for key, value in train_dataset.loaded_entity_to_idx.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (\n",
    "            batched_subgraphs,\n",
    "            question_embeddings,\n",
    "            stacked_labels,\n",
    "            node_maps,\n",
    "            labels,\n",
    "            paths\n",
    "        ) in tqdm(dataloader, desc=\"Extracting subgraph\", leave=True):\n",
    "            # Perform forward pass\n",
    "            batched_subgraphs = batched_subgraphs.to(device)\n",
    "            question_embeddings = question_embeddings.to(device)\n",
    "            full_output = model(batched_subgraphs, question_embeddings)\n",
    "\n",
    "            # Extract relevant outputs\n",
    "            output = full_output.output if hasattr(full_output, \"output\") else full_output\n",
    "            threshold = full_output.threshold if hasattr(full_output, \"threshold\") else threshold_value\n",
    "            candidates_mask, _ = threshold_based_candidates(output, threshold=threshold)\n",
    "\n",
    "            # Unpack the node_maps tuple to access the dictionary\n",
    "            node_maps_dict = node_maps[0] if isinstance(node_maps, tuple) else node_maps\n",
    "\n",
    "            # Extract the values of nodes that are marked as candidates (masked as 1)\n",
    "            high_similarity_indices = (candidates_mask == 1).nonzero(as_tuple=True)[0]\n",
    "            candidate_values_batch = []\n",
    "            for idx in high_similarity_indices:\n",
    "                original_node_value = list(node_maps_dict.keys())[idx.item()]\n",
    "                original_node_value = reversed_index[original_node_value]\n",
    "                candidate_values_batch.append(original_node_value)\n",
    "            all_candidate_values.append(candidate_values_batch)\n",
    "\n",
    "            \n",
    "            all_paths.append(paths)\n",
    "    return all_paths[0][0], all_candidate_values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cceb4071",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5926701c",
   "metadata": {},
   "source": [
    "Train dataset is loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c90a6e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78723191f7954980a7bda32d4f9b1e90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/338 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07cc0370e28245f2acf05ac6b17a5ff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/930 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = KGQADataset(\n",
    "    path_to_node_embed=config['node_embed'],\n",
    "    path_to_idxes=config['idxes'],\n",
    "    path_to_qa=config['train_qa_data'],\n",
    "    path_to_kb=config['raw_kb'],\n",
    "    from_paths_activate=True,\n",
    "    entity_sbert=False,\n",
    "    k=config['num_hops']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95920d8a",
   "metadata": {},
   "source": [
    "The following index is chosen for demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f56d1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_ind = 50004\n",
    "end_ind =50005"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b87d066",
   "metadata": {},
   "source": [
    "Question and ground truth answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b074e23f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: who is listed as director of [Hiromi Nagasaku] acted films\n",
      "Ground Truth Answer: ['Kiyoshi Kurosawa']\n"
     ]
    }
   ],
   "source": [
    "question = train_dataset.df.iloc[start_ind:end_ind]['question'].tolist()[0]\n",
    "ground_truth_answers = train_dataset.df.iloc[start_ind:end_ind]['answer'].tolist()[0]\n",
    "\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Ground Truth Answer: {ground_truth_answers}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f7bbad",
   "metadata": {},
   "source": [
    "The batch of specific index is loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8fed52a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_relations = train_dataset.num_relations\n",
    "sub_train_dataset = Subset(train_dataset, list(range(start_ind,end_ind)))\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    sub_train_dataset,\n",
    "    batch_size=config['train']['batch_size'],\n",
    "    collate_fn=collate_fn,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01ecaed",
   "metadata": {},
   "source": [
    "Load pretrained GNN for output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a08c31b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_279696/11342916.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(config['model_path_test2'])\n"
     ]
    }
   ],
   "source": [
    "model_test2 = RGCNModel(\n",
    "            node_dim=config['model']['in_channels'],\n",
    "            question_dim=train_dataset.q_embeddings.size(-1),\n",
    "            hidden_dim=config['model']['hidden_channels'],\n",
    "            num_relations=38,\n",
    "            output_dim=config['model']['out_channels'],\n",
    "            num_rgcn=config['model']['num_layers'],\n",
    "            reduced_qn_dim=config['model']['reduced_qn_dim'],\n",
    "            reduced_node_dim=config['model']['reduced_node_dim'],\n",
    "            output_embedding=config['model']['output_embedding'],\n",
    "            use_residuals=config['model']['use_residuals']\n",
    "        )\n",
    "\n",
    "checkpoint = torch.load(config['model_path_test2'])\n",
    "model_test2.load_state_dict(checkpoint['model_state_dict'])\n",
    "model_test2 = model_test2.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69061cde",
   "metadata": {},
   "source": [
    "Load output specific configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "680d0ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "equal_subgraph_weighting = config['train']['equal_subgraph_weighting']\n",
    "threshold_value = 0.50\n",
    "hits_at_k = config['train']['hits_at_k']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a46f455",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting subgraph:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd41c75979d3438ab45c6533dcb2d3d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting subgraph: 100%|██████████| 1/1 [00:00<00:00, 12.62it/s]\n"
     ]
    }
   ],
   "source": [
    "paths, candidate_nodes = extract_candidate_nodes_and_paths(train_loader, model_test2, device, threshold_value, train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f59d5c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Comedy',\n",
       " '1993',\n",
       " '2003',\n",
       " 'Drew Barrymore',\n",
       " 'Kiyoshi Kurosawa',\n",
       " 'Doppelganger',\n",
       " 'Hiromi Nagasaku']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b75b8a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Hiromi Nagasaku', 'starring'),\n",
       "  ('Doppelganger', 'release year'),\n",
       "  ('1993', None)],\n",
       " [('Hiromi Nagasaku', 'starring'),\n",
       "  ('Doppelganger', 'release year'),\n",
       "  ('2003', None)],\n",
       " [('Hiromi Nagasaku', 'starring'),\n",
       "  ('Doppelganger', 'has genre'),\n",
       "  ('Comedy', None)],\n",
       " [('Hiromi Nagasaku', 'starring'),\n",
       "  ('Doppelganger', 'starred actors'),\n",
       "  ('Drew Barrymore', None)],\n",
       " [('Hiromi Nagasaku', 'starring'),\n",
       "  ('Doppelganger', 'in language'),\n",
       "  ('Japanese', None)],\n",
       " [('Hiromi Nagasaku', 'starring'),\n",
       "  ('Doppelganger', 'directed by and written by'),\n",
       "  ('Kiyoshi Kurosawa', None)],\n",
       " [('Hiromi Nagasaku', 'starring'), ('Doppelganger', None)]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e148a602",
   "metadata": {},
   "source": [
    "# RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "32b91fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fcbad3",
   "metadata": {},
   "source": [
    "Load Llama3.1 as LLM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "562b359c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54001684d309480c9111fab2939cf00b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm_tokenizer = AutoTokenizer.from_pretrained(\"/hpctmp/e0315913/transformers_cache/models--akjindal53244--Llama-3.1-Storm-8B/snapshots/df21b06dcf534b026dd301a44a521d7253c8b94b\")\n",
    "llm_model = AutoModelForCausalLM.from_pretrained(\"/hpctmp/e0315913/transformers_cache/models--akjindal53244--Llama-3.1-Storm-8B/snapshots/df21b06dcf534b026dd301a44a521d7253c8b94b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0e496b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def create_prompt(question, paths, candidate_answers):\n",
    "    \"\"\"\n",
    "    Formats the question and candidate paths into a prompt.\n",
    "    \"\"\"\n",
    "    prompt = f\"You are doing extractive question answering. Strictly use the following pieces of context to choose correct candidate answer to the question from Candidate Answers. Answer directly, without elaboration. Output in comma-separated form.\\n\"\n",
    "    prompt += f\"Question: {question}\\nPaths:\\n\"\n",
    "    for path in paths:\n",
    "        prompt += f\"- {path}\\n\"\n",
    "    prompt += f\"Candidate Answers: {candidate_answers}\\n\"\n",
    "    prompt += \"Answer: \"\n",
    "    return prompt\n",
    "\n",
    "def query_llm(question, paths, candidate_answers):\n",
    "    \"\"\"\n",
    "    Queries the LLM with the formatted question and paths.\n",
    "    \"\"\"\n",
    "    prompt = create_prompt(question, paths, candidate_answers)\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    \n",
    "    llm_model.to(\"cpu\")\n",
    "    inputs = llm_tokenizer(prompt, return_tensors=\"pt\").to(\"cpu\")\n",
    "    \n",
    "    prompt_length = inputs.input_ids.size(1)\n",
    "    max_length = prompt_length + 50\n",
    "    outputs = llm_model.generate(\n",
    "        **inputs,\n",
    "        max_length=max_length,\n",
    "        num_return_sequences=1,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        top_k=50,\n",
    "        no_repeat_ngram_size=3,\n",
    "        pad_token_id=llm_tokenizer.eos_token_id\n",
    "    )\n",
    "    decoded_outputs = llm_tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    full_response = decoded_outputs[0]\n",
    "    match = re.search(r\"Answer:\\s*(.*?)(?:[\\n]|$)\", full_response, re.IGNORECASE)\n",
    "    if match:\n",
    "        response = match.group(1).strip()\n",
    "    else:\n",
    "        response = full_response.strip()\n",
    "    response = response.split('.')[0]\n",
    "    response = response.replace(\"\\n\", \"\").replace(\" and \", \", \").strip()\n",
    "    response = \", \".join([genre.strip().capitalize() for genre in response.split(\",\")])\n",
    "    response = extract_unique_comma_separated(response, candidate_answers)\n",
    "    print(f\"{response}\\n\")\n",
    "    return response\n",
    "\n",
    "def format_paths_for_llm(candidate_paths):\n",
    "    formatted_paths = []\n",
    "    for path in candidate_paths:\n",
    "        path_sentence = \" -> \".join(\n",
    "            f\"{node} {relation}\" if relation else f\"{node}\" for node, relation in path\n",
    "        )\n",
    "        formatted_paths.append(path_sentence)\n",
    "    return formatted_paths\n",
    "\n",
    "def extract_unique_comma_separated(input_string, candidate_answers):\n",
    "    items = [item.strip() for item in input_string.split(\",\")]\n",
    "    unique_items = list(set(items))\n",
    "    unique_items.sort()\n",
    "    result = \", \".join(unique_items)\n",
    "    input_string = input_string.lower()\n",
    "    final_answers = []\n",
    "    for answers in candidate_answers:\n",
    "        answers_string = answers.lower().split()\n",
    "        for answer in answers_string:\n",
    "            if answer in input_string:\n",
    "                final_answers.append(answers)\n",
    "                break\n",
    "    final_answers = \", \".join(final_answers)\n",
    "    return final_answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901e3737",
   "metadata": {},
   "source": [
    "## Candidate Paths Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "31fdb9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entity_from_question(question):\n",
    "    start = question.find(\"[\") + 1\n",
    "    end = question.find(\"]\")\n",
    "    if start == 0 or end == -1:\n",
    "        raise ValueError(f\"No entity found in the question: {question}\")\n",
    "    return question[start:end]\n",
    "\n",
    "\n",
    "def filter_path_with_entity(entity, candidate_paths):\n",
    "    filtered_path = []\n",
    "    for path in candidate_paths:\n",
    "        if path[0][0] == entity:\n",
    "            filtered_path.append(path)\n",
    "    return filtered_path\n",
    "\n",
    "\n",
    "def filter_path_with_candidate_node(candidate_nodes, filtered_paths, question_entity):\n",
    "    if question_entity in candidate_nodes:\n",
    "        candidate_nodes.remove(question_entity)\n",
    "    return [\n",
    "        path\n",
    "        for path in filtered_paths\n",
    "        if any(path[-1][0] == node for node in candidate_nodes)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85807a66",
   "metadata": {},
   "source": [
    "Extracting paths from subgraph that starts with question entity and ends with candidate nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "989dd9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_entity = extract_entity_from_question(question)\n",
    "filtered_path = filter_path_with_entity(question_entity, paths)\n",
    "final_candidate_paths = filter_path_with_candidate_node(candidate_nodes,filtered_path,question_entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "508ea4e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Hiromi Nagasaku', 'starring'),\n",
       "  ('Doppelganger', 'release year'),\n",
       "  ('1993', None)],\n",
       " [('Hiromi Nagasaku', 'starring'),\n",
       "  ('Doppelganger', 'release year'),\n",
       "  ('2003', None)],\n",
       " [('Hiromi Nagasaku', 'starring'),\n",
       "  ('Doppelganger', 'has genre'),\n",
       "  ('Comedy', None)],\n",
       " [('Hiromi Nagasaku', 'starring'),\n",
       "  ('Doppelganger', 'starred actors'),\n",
       "  ('Drew Barrymore', None)],\n",
       " [('Hiromi Nagasaku', 'starring'),\n",
       "  ('Doppelganger', 'directed by and written by'),\n",
       "  ('Kiyoshi Kurosawa', None)],\n",
       " [('Hiromi Nagasaku', 'starring'), ('Doppelganger', None)]]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_candidate_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8897a50",
   "metadata": {},
   "source": [
    "Formatting paths for LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eb7bc94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_paths = format_paths_for_llm(final_candidate_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "88c80806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hiromi Nagasaku starring -> Doppelganger release year -> 1993',\n",
       " 'Hiromi Nagasaku starring -> Doppelganger release year -> 2003',\n",
       " 'Hiromi Nagasaku starring -> Doppelganger has genre -> Comedy',\n",
       " 'Hiromi Nagasaku starring -> Doppelganger starred actors -> Drew Barrymore',\n",
       " 'Hiromi Nagasaku starring -> Doppelganger directed by and written by -> Kiyoshi Kurosawa',\n",
       " 'Hiromi Nagasaku starring -> Doppelganger']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c43d52b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: You are doing extractive question answering. Strictly use the following pieces of context to choose correct candidate answer to the question from Candidate Answers. Answer directly, without elaboration. Output in comma-separated form.\n",
      "Question: who is listed as director of [Hiromi Nagasaku] acted films\n",
      "Paths:\n",
      "- Hiromi Nagasaku starring -> Doppelganger release year -> 1993\n",
      "- Hiromi Nagasaku starring -> Doppelganger release year -> 2003\n",
      "- Hiromi Nagasaku starring -> Doppelganger has genre -> Comedy\n",
      "- Hiromi Nagasaku starring -> Doppelganger starred actors -> Drew Barrymore\n",
      "- Hiromi Nagasaku starring -> Doppelganger directed by and written by -> Kiyoshi Kurosawa\n",
      "- Hiromi Nagasaku starring -> Doppelganger\n",
      "Candidate Answers: ['Comedy', '1993', '2003', 'Drew Barrymore', 'Kiyoshi Kurosawa', 'Doppelganger']\n",
      "Answer: \n",
      "Kiyoshi Kurosawa\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = query_llm(question, formatted_paths, candidate_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4090ef80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: who is listed as director of [Hiromi Nagasaku] acted films\n",
      "Ground Truth Answer: ['Kiyoshi Kurosawa']\n",
      "GNN+LLM Generated Answer: Kiyoshi Kurosawa\n"
     ]
    }
   ],
   "source": [
    "print(f\"Question: {question}\")\n",
    "print(f\"Ground Truth Answer: {ground_truth_answers}\")\n",
    "print(f\"GNN+LLM Generated Answer: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605887cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
