{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<pyximport._pyximport3.PyImportMetaFinder at 0x7f9056223400>,\n",
       " <pyximport._pyximport3.PyxImportMetaFinder at 0x7f90562234c0>)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cython Speed up\n",
    "import pyximport\n",
    "\n",
    "pyximport.install(pyimport=True, language_level=\"3\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Entities and Relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity1</th>\n",
       "      <th>relation</th>\n",
       "      <th>entity2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kismet</td>\n",
       "      <td>directed_by</td>\n",
       "      <td>William Dieterle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kismet</td>\n",
       "      <td>written_by</td>\n",
       "      <td>Edward Knoblock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kismet</td>\n",
       "      <td>starred_actors</td>\n",
       "      <td>Marlene Dietrich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kismet</td>\n",
       "      <td>starred_actors</td>\n",
       "      <td>Edward Arnold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kismet</td>\n",
       "      <td>starred_actors</td>\n",
       "      <td>Ronald Colman</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  entity1        relation           entity2\n",
       "0  Kismet     directed_by  William Dieterle\n",
       "1  Kismet      written_by   Edward Knoblock\n",
       "2  Kismet  starred_actors  Marlene Dietrich\n",
       "3  Kismet  starred_actors     Edward Arnold\n",
       "4  Kismet  starred_actors     Ronald Colman"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "path = '../Datasets/MetaQA_dataset/'\n",
    "\n",
    "df = pd.read_csv(path+'kb.txt', sep='|', header=None, names=['entity1', 'relation', 'entity2'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 249349], relation=[249349], num_nodes=43234)\n",
      "[('Kismet', 'William Dieterle', {'relation': 'directed_by'}), ('Kismet', 'Edward Knoblock', {'relation': 'written_by'})]\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from torch_geometric.utils import from_networkx\n",
    "\n",
    "# Create a NetworkX graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Iterate over the DataFrame and add edges\n",
    "for idx, row in df.iterrows():\n",
    "    entity1 = row['entity1']\n",
    "    entity2 = row['entity2']\n",
    "    relation = row['relation']\n",
    "\n",
    "    # Add edge with relation as edge attribute\n",
    "    G.add_edge(entity1, entity2, relation=relation)\n",
    "\n",
    "# Convert to a PyTorch Geometric Data object\n",
    "data = from_networkx(G)\n",
    "\n",
    "# Print the PyTorch Geometric Data object\n",
    "print(data)\n",
    "\n",
    "# Print first N edges to verify\n",
    "N = 2\n",
    "edges = list(G.edges(data=True))[:N]\n",
    "print(edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import node embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Number of nodes (entities)\n",
    "num_nodes = G.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Drama', 'Comedy', 'Horror', 'Thriller', 'bd-r']\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([43234, 64])\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "file_path = '../MetaQA/ud_node2vec_embeddings.txt'  # Replace with your file path\n",
    "\n",
    "# Define lists to store the node IDs and their embeddings\n",
    "node_ids = []\n",
    "embeddings = []\n",
    "\n",
    "# Open and read the file\n",
    "with open(file_path, 'r') as file:\n",
    "    reader = csv.reader(file, delimiter=' ')\n",
    "    for line_num, row in enumerate(reader):\n",
    "        # Store everything except the last 64 elements as the \"node ID\"\n",
    "        node_ids.append(' '.join(row[:-64]))  # Join multiple elements if they exist before the last 64\n",
    "\n",
    "        # Store the last 64 elements as the \"embeddings\"\n",
    "        embeddings.append([float(x) for x in row[-64:]])  # Convert embeddings to floats\n",
    "\n",
    "node_ids.pop(0)\n",
    "embeddings.pop(0)\n",
    "embeddings = torch.tensor(embeddings, dtype=torch.float)\n",
    "\n",
    "print(node_ids[0:5])\n",
    "print(type(embeddings))  # Check the type\n",
    "print(embeddings.shape)  # Check the embedding dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map node embeddings to graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Drama', 0), ('Comedy', 1), ('Horror', 2), ('Thriller', 3), ('bd-r', 4)]\n",
      "graph_node_order:['Kismet', 'William Dieterle', 'Edward Knoblock', 'Marlene Dietrich', 'Edward Arnold']\n"
     ]
    }
   ],
   "source": [
    "# Create a mapping from node ID to index in the node embedding tensor\n",
    "node_to_index = {node: idx for idx, node in enumerate(node_ids)}\n",
    "\n",
    "# Visualize the first n items\n",
    "print(list(node_to_index.items())[0:5])\n",
    "\n",
    "# Ensure that the node order in the graph matches the order in the embeddings\n",
    "graph_node_order = list(G.nodes())  # Order of nodes in the graph\n",
    "print(f\"graph_node_order:{graph_node_order[0:5]}\")\n",
    "\n",
    "graph_node_embeddings = torch.zeros((len(graph_node_order), embeddings.shape[1]))\n",
    "\n",
    "\n",
    "for idx, node in enumerate(graph_node_order):\n",
    "    if node in node_to_index:\n",
    "        graph_node_embeddings[idx] = embeddings[node_to_index[node]]\n",
    "    else:\n",
    "        print(f\"Warning: Node {node} not found in embedding file.\")\n",
    "\n",
    "# Assign these embeddings as the node features (x) in the PyTorch Geometric Data object\n",
    "data.x = graph_node_embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import QA training datasetS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(114196, 2) (114196, 1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the question-answer pairs from qa_train.txt\n",
    "qa_file = '../Datasets/MetaQA_dataset/vanilla 3-hop/qa_train.txt'\n",
    "qa_df = pd.read_csv(qa_file, sep='\\t', header=None, names=['question', 'answers'])\n",
    "\n",
    "# Load the relation types from qa_train_qtype.txt\n",
    "qa_qtype_file = '../Datasets/MetaQA_dataset/vanilla 3-hop/qa_train_qtype.txt'\n",
    "qa_qtype_df = pd.read_csv(qa_qtype_file, sep='\\t', header=None, names=['relation_type'])\n",
    "\n",
    "# Ensure both files are aligned\n",
    "print(qa_df.shape, qa_qtype_df.shape)  # They should have the same number of rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "      <th>relation_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the films that share actors with the film [Dil...</td>\n",
       "      <td>1997|1998|2003|2001|2006|2004|2005|2014|2008|2...</td>\n",
       "      <td>movie_to_actor_to_movie_to_year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>who are the directors of the movies written by...</td>\n",
       "      <td>Stephen King|Frank Darabont|Tobe Hooper|Mick G...</td>\n",
       "      <td>movie_to_writer_to_movie_to_director</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>which person directed the films acted by the a...</td>\n",
       "      <td>Chris D'Arienzo|Jonathan Kesselman|Joe Chappel...</td>\n",
       "      <td>movie_to_actor_to_movie_to_director</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>who is listed as director of the movies starre...</td>\n",
       "      <td>Chris Columbus|David Yates|Alfonso Cuarón|Mike...</td>\n",
       "      <td>movie_to_actor_to_movie_to_director</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what types are the films directed by the direc...</td>\n",
       "      <td>Action|Comedy|Western|Thriller|Crime</td>\n",
       "      <td>movie_to_director_to_movie_to_genre</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  the films that share actors with the film [Dil...   \n",
       "1  who are the directors of the movies written by...   \n",
       "2  which person directed the films acted by the a...   \n",
       "3  who is listed as director of the movies starre...   \n",
       "4  what types are the films directed by the direc...   \n",
       "\n",
       "                                             answers  \\\n",
       "0  1997|1998|2003|2001|2006|2004|2005|2014|2008|2...   \n",
       "1  Stephen King|Frank Darabont|Tobe Hooper|Mick G...   \n",
       "2  Chris D'Arienzo|Jonathan Kesselman|Joe Chappel...   \n",
       "3  Chris Columbus|David Yates|Alfonso Cuarón|Mike...   \n",
       "4               Action|Comedy|Western|Thriller|Crime   \n",
       "\n",
       "                          relation_type  \n",
       "0       movie_to_actor_to_movie_to_year  \n",
       "1  movie_to_writer_to_movie_to_director  \n",
       "2   movie_to_actor_to_movie_to_director  \n",
       "3   movie_to_actor_to_movie_to_director  \n",
       "4   movie_to_director_to_movie_to_genre  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the two DataFrames\n",
    "qa_combined_df = pd.concat([qa_df, qa_qtype_df], axis=1)\n",
    "\n",
    "# Check the combined DataFrame\n",
    "qa_combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'start_entity_idx': 5123, 'relation_steps': 'movie_to_director_to_movie_to_genre', 'answer_indices': [46, 157, 119, 52, 618]}\n",
      "Time taken: 261.49 seconds\n",
      "Missing entities: []\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import torch\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Regular expression to extract entities enclosed in square brackets\n",
    "entity_pattern = re.compile(r'\\[(.*?)\\]')\n",
    "\n",
    "# Store question-related data for training the GNN\n",
    "question_data = []\n",
    "missing_entities = []  # Track missing entities\n",
    "\n",
    "# Function to process each question\n",
    "def process_question(row):\n",
    "    question = row['question']\n",
    "    answers = row['answers'].split('|')  # List of correct answers\n",
    "    relation_steps = row['relation_type']  # The relation type from qa_train_qtype.txt\n",
    "\n",
    "    # Extract entities enclosed in square brackets and normalize\n",
    "    entities = entity_pattern.findall(question)\n",
    "\n",
    "    if not entities:\n",
    "        return None  # Skip if no entity found\n",
    "\n",
    "    start_entity = entities[0]\n",
    "    # start_entity = entities[0].strip().lower()  # Normalize start entity\n",
    "\n",
    "    # Find the index of the start entity in the graph\n",
    "    if start_entity not in graph_node_order:\n",
    "        print(f\"Warning: Start entity '{start_entity}' not found in graph.\")\n",
    "        missing_entities.append(start_entity)  # Track missing entity\n",
    "        return None\n",
    "\n",
    "    start_entity_idx = graph_node_order.index(start_entity)\n",
    "\n",
    "    # Find the indices of the answer nodes and normalize answers\n",
    "    answer_indices = []\n",
    "    for answer in answers:\n",
    "        # answer = answer.strip().lower()  # Normalize answer\n",
    "        if answer in graph_node_order:\n",
    "            answer_idx = graph_node_order.index(answer)\n",
    "            answer_indices.append(answer_idx)\n",
    "        else:\n",
    "            print(f\"Warning: Answer '{answer}' not found in graph.\")\n",
    "            missing_entities.append(answer)  # Track missing answer entity\n",
    "\n",
    "    # Return the start entity index, relation steps, and answer indices for this question\n",
    "    return {\n",
    "        'start_entity_idx': start_entity_idx,\n",
    "        'relation_steps': relation_steps,  # Now using the split relation steps directly\n",
    "        'answer_indices': answer_indices\n",
    "    }\n",
    "\n",
    "# Process the data in parallel\n",
    "max_workers = os.cpu_count()  # Number of available CPU cores\n",
    "start_time = time.time()  # Track start time\n",
    "\n",
    "# Collect results safely\n",
    "results = []\n",
    "with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "    futures = [executor.submit(process_question, row) for idx, row in qa_combined_df.iterrows()]\n",
    "\n",
    "    for future in as_completed(futures):\n",
    "        result = future.result()\n",
    "        if result:\n",
    "            results.append(result)\n",
    "\n",
    "# Append all results at once\n",
    "question_data.extend(results)\n",
    "\n",
    "# Now 'question_data' contains the necessary info for training\n",
    "# Each entry contains the start entity index, relation steps, and the list of answer indices\n",
    "\n",
    "# Visualize an entry\n",
    "print(question_data[0])\n",
    "\n",
    "end_time = time.time()  # Track end time\n",
    "elapsed_time = end_time - start_time  # Print the time taken\n",
    "print(f\"Time taken: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "# Optionally: print missing entities\n",
    "print(f\"Missing entities: {missing_entities}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define GNN structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GNNModel(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GNNModel, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 16)\n",
    "        self.conv2 = GCNConv(16, out_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define training regime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Check if a GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Move the model to the GPU\n",
    "model = GNNModel(in_channels=64, out_channels=2).to(device)\n",
    "\n",
    "# Move the data to the GPU\n",
    "data = data.to(device)\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mapping in Python\n",
    "relation_mapping = {\n",
    "    'movie_to_actor_to_movie_to_year': ['starred_actors', 'starred_actors', 'release_year'],\n",
    "    'movie_to_writer_to_movie_to_director': ['written_by', 'written_by', 'directed_by'],\n",
    "    'movie_to_actor_to_movie_to_director': ['starred_actors', 'starred_actors', 'directed_by'],\n",
    "    'movie_to_director_to_movie_to_genre': ['directed_by', 'directed_by', 'has_genre'],\n",
    "    'movie_to_actor_to_movie_to_writer': ['starred_actors', 'starred_actors', 'written_by'],\n",
    "    'movie_to_director_to_movie_to_language': ['directed_by', 'directed_by', 'in_language'],\n",
    "    'movie_to_writer_to_movie_to_actor': ['written_by', 'written_by', 'starred_actors'],\n",
    "    'movie_to_director_to_movie_to_actor': ['directed_by', 'directed_by', 'starred_actors'],\n",
    "    'movie_to_actor_to_movie_to_language': ['starred_actors', 'starred_actors', 'in_language'],\n",
    "    'movie_to_director_to_movie_to_year': ['directed_by', 'directed_by', 'release_year'],\n",
    "    'movie_to_actor_to_movie_to_genre': ['starred_actors', 'starred_actors', 'has_genre'],\n",
    "    'movie_to_director_to_movie_to_writer': ['directed_by', 'directed_by', 'written_by'],\n",
    "    'movie_to_writer_to_movie_to_genre': ['written_by', 'written_by', 'has_genre'],\n",
    "    'movie_to_writer_to_movie_to_year': ['written_by', 'written_by', 'release_year'],\n",
    "    'movie_to_writer_to_movie_to_language': ['written_by', 'written_by', 'in_language']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_relation_steps(relation_steps, relation_mapping):\n",
    "    # Translate the entire relation string into its specific edge types\n",
    "    return relation_mapping.get(relation_steps, relation_steps)  # Use mapping, or return the original if not found\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Troubleshooting (start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q = question_data[0]\n",
    "\n",
    "# start_entity_idx = q['start_entity_idx']\n",
    "# relation_steps2 = q['relation_steps']  # Extract the parsed relation steps\n",
    "# answer_indices = q['answer_indices']\n",
    "\n",
    "# # Translate relation steps to actual edge types in the graph\n",
    "# relation_steps = translate_relation_steps(relation_steps2, relation_mapping)\n",
    "\n",
    "# # Get the start entity name from the global node list (graph_node_order)\n",
    "# start_entity = graph_node_order[start_entity_idx]\n",
    "\n",
    "# # Get the neighbors within 'hops' distance from the start entity\n",
    "# sub_nodes = nx.single_source_shortest_path_length(G, start_entity, cutoff=3).keys()\n",
    "\n",
    "# # Extract the subgraph from the main graph\n",
    "# subgraph = G.subgraph(sub_nodes).copy()\n",
    "\n",
    "# # Filter edges based on each step of the translated relation type\n",
    "# filtered_edges = []\n",
    "# for u, v, d in subgraph.edges(data=True):\n",
    "#     # Check if the relation exists in the edge data and matches the translated steps\n",
    "#     if 'relation' in d and d['relation'] in relation_steps:\n",
    "#         filtered_edges.append((u, v))\n",
    "\n",
    "# # Create a new filtered subgraph with only the relevant edges\n",
    "# subgraph_filtered = subgraph.edge_subgraph(filtered_edges).copy()\n",
    "\n",
    "# # Convert the filtered subgraph to a PyTorch Geometric Data object\n",
    "# data_subgraph = from_networkx(subgraph_filtered)\n",
    "\n",
    "# # Store the global node IDs as a list instead of\n",
    "# data_subgraph.global_node_id = list(subgraph_filtered.nodes)\n",
    "\n",
    "# subgraph_node_indices = [graph_node_order.index(node) for node in subgraph_filtered.nodes]\n",
    "\n",
    "# # Extract and assign the node features (embeddings) from the full graph's data.x\n",
    "# data_subgraph.x = data.x[subgraph_node_indices].to(device)  # Use the corresponding node embeddings from the full graph\n",
    "# subgraph_data = data_subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for answer_idx in answer_indices:\n",
    "#     # Map global answer_idx to the local subgraph node\n",
    "#     if answer_idx in subgraph_data.global_node_id:\n",
    "#         local_answer_idx = subgraph_data.global_node_id.index(answer_idx)  # Get the local index\n",
    "#         subgraph_data.y[local_answer_idx] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subgraph_node_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subgraph_filtered.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subgraph_node_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Troubleshooting (end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_subgraph_with_relation_steps(start_entity_idx, G, data, relation_steps, hops=3):\n",
    "#     # Translate relation steps to actual edge types in the graph\n",
    "#     relation_steps = translate_relation_steps(relation_steps, relation_mapping)\n",
    "\n",
    "#     # Get the start entity name from the global node list (graph_node_order)\n",
    "#     start_entity = graph_node_order[start_entity_idx]\n",
    "\n",
    "#     # Get the neighbors within 'hops' distance from the start entity\n",
    "#     sub_nodes = nx.single_source_shortest_path_length(G, start_entity, cutoff=hops).keys()\n",
    "\n",
    "#     # Extract the subgraph from the main graph\n",
    "#     subgraph = G.subgraph(sub_nodes).copy()\n",
    "\n",
    "#     # Filter edges based on each step of the translated relation type\n",
    "#     filtered_edges = []\n",
    "#     for u, v, d in subgraph.edges(data=True):\n",
    "#         # Check if the relation exists in the edge data and matches the translated steps\n",
    "#         if 'relation' in d and d['relation'] in relation_steps:\n",
    "#             filtered_edges.append((u, v))\n",
    "\n",
    "#     # Create a new filtered subgraph with only the relevant edges\n",
    "#     subgraph_filtered = subgraph.edge_subgraph(filtered_edges).copy()\n",
    "\n",
    "#     # Convert the filtered subgraph to a PyTorch Geometric Data object\n",
    "#     data_subgraph = from_networkx(subgraph_filtered)\n",
    "\n",
    "#     # Store the global node IDs as a list instead of a tensor\n",
    "#     data_subgraph.global_node_id = list(subgraph_filtered.nodes)\n",
    "\n",
    "#     # Ensure that the node order in the subgraph matches the embeddings in the original graph\n",
    "#     subgraph_node_indices = [graph_node_order.index(node) for node in subgraph_filtered.nodes]\n",
    "\n",
    "#     # Extract and assign the node features (embeddings) from the full graph's data.x\n",
    "#     data_subgraph.x = data.x[subgraph_node_indices].to(device)  # Use the corresponding node embeddings from the full graph\n",
    "\n",
    "#     return data_subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subgraph_with_relation_steps(start_entity_idx, G, data, relation_steps, hops=3):\n",
    "    # Translate relation steps to actual edge types in the graph\n",
    "    relation_steps = translate_relation_steps(relation_steps, relation_mapping)\n",
    "\n",
    "    # Get the start entity name from the global node list (graph_node_order)\n",
    "    start_entity = graph_node_order[start_entity_idx]\n",
    "\n",
    "    # Get the neighbors within 'hops' distance from the start entity\n",
    "    sub_nodes = nx.single_source_shortest_path_length(G, start_entity, cutoff=hops).keys()\n",
    "\n",
    "    # Extract the subgraph from the main graph\n",
    "    subgraph = G.subgraph(sub_nodes).copy()\n",
    "\n",
    "    # Filter edges based on each step of the translated relation type\n",
    "    filtered_edges = []\n",
    "    for u, v, d in subgraph.edges(data=True):\n",
    "        # Check if the relation exists in the edge data and matches the translated steps\n",
    "        if 'relation' in d and d['relation'] in relation_steps:\n",
    "            filtered_edges.append((u, v))\n",
    "\n",
    "    # Create a new filtered subgraph with only the relevant edges\n",
    "    subgraph_filtered = subgraph.edge_subgraph(filtered_edges).copy()\n",
    "\n",
    "    # Convert the filtered subgraph to a PyTorch Geometric Data object\n",
    "    data_subgraph = from_networkx(subgraph_filtered)\n",
    "\n",
    "    # Ensure that the node order in the subgraph matches the embeddings in the original graph\n",
    "    subgraph_node_indices = [graph_node_order.index(node) for node in subgraph_filtered.nodes]\n",
    "\n",
    "    # Store the global node indices (which are integers, not strings) in global_node_id\n",
    "    data_subgraph.global_node_id = subgraph_node_indices\n",
    "\n",
    "    # Extract and assign the node features (embeddings) from the full graph's data.x\n",
    "    data_subgraph.x = data.x[subgraph_node_indices].to(device)  # Use the corresponding node embeddings from the full graph\n",
    "\n",
    "    return data_subgraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_gnn_with_subgraph(question_data, data, G, use_full_graph=False):\n",
    "#     model.train()\n",
    "#     total_loss = 0\n",
    "#     missing_answer = 0\n",
    "#     c = 0\n",
    "\n",
    "#     # Ensure the full graph also has global_node_id if using full graph\n",
    "#     if use_full_graph and not hasattr(data, 'global_node_id'):\n",
    "#         # Create global_node_id for the full graph, which is the full list of node indices\n",
    "#         graph_node_indices = [graph_node_order.index(node) for node in G.nodes]\n",
    "#         data.global_node_id = graph_node_indices\n",
    "\n",
    "\n",
    "#     for q in question_data:\n",
    "#         c += 1\n",
    "\n",
    "#         start_entity_idx = q['start_entity_idx']\n",
    "#         relation_steps = q['relation_steps']  # Extract the parsed relation steps\n",
    "#         answer_indices = q['answer_indices']\n",
    "\n",
    "#         if use_full_graph:\n",
    "#             # Use the entire graph for training\n",
    "#             subgraph_data = data  # Use the full graph's data\n",
    "#         else:\n",
    "#             # Get the subgraph centered around the start entity and filtered by relation steps\n",
    "#             subgraph_data = get_subgraph_with_relation_steps(start_entity_idx, G, data, relation_steps, hops=20)\n",
    "\n",
    "#         # Move the graph data (either full or subgraph) to the correct device (e.g., GPU)\n",
    "#         subgraph_data = subgraph_data.to(device)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         # Forward pass through the GNN model (on the full graph or subgraph)\n",
    "#         out = model(subgraph_data)  # Model predicts scores for all nodes in the (sub)graph\n",
    "\n",
    "#         # Initialize subgraph_data.y (labels) to be all zeros (for the subgraph or full graph nodes)\n",
    "#         subgraph_data.y = torch.zeros(subgraph_data.num_nodes, dtype=torch.long).to(device)\n",
    "\n",
    "#         # Mark the correct answer nodes in the graph as 1\n",
    "#         for answer_idx in answer_indices:\n",
    "#             # Map global answer_idx to the local subgraph node\n",
    "#             if answer_idx in subgraph_data.global_node_id:\n",
    "#                 local_answer_idx = subgraph_data.global_node_id.index(answer_idx)  # Get the local index\n",
    "#                 subgraph_data.y[local_answer_idx] = 1\n",
    "#             else:\n",
    "#                 missing_answer += 1\n",
    "#                 print(f\"Warning: Answer node {answer_idx} not found in the (sub)graph; counter: {missing_answer}; question_data: {c}\")\n",
    "\n",
    "#         # Compute the loss (CrossEntropy between the predicted outputs and actual labels)\n",
    "#         loss = criterion(out, subgraph_data.y)\n",
    "#         loss.backward()  # Backpropagate the gradients\n",
    "#         optimizer.step()  # Update model parameters\n",
    "\n",
    "#         total_loss += loss.item()\n",
    "\n",
    "#     return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (A)\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_gnn_with_subgraph(question_data, data, G, use_full_graph=False):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    missing_answer = 0\n",
    "    c = 0\n",
    "\n",
    "    # Precompute global node IDs as a dictionary for fast lookups\n",
    "    global_node_id_map = {node: idx for idx, node in enumerate(graph_node_order)}\n",
    "\n",
    "    # Ensure the full graph also has global_node_id if using full graph\n",
    "    if use_full_graph and not hasattr(data, 'global_node_id'):\n",
    "        # Assign global_node_id for the full graph\n",
    "        data.global_node_id = [global_node_id_map[node] for node in G.nodes]\n",
    "\n",
    "    # Wrap question_data in tqdm to display a progress bar\n",
    "    for q in tqdm(question_data, desc=\"Training Progress\"):\n",
    "        c += 1\n",
    "\n",
    "        start_entity_idx = q['start_entity_idx']\n",
    "        relation_steps = q['relation_steps']  # Extract the parsed relation steps\n",
    "        answer_indices = q['answer_indices']\n",
    "\n",
    "        if use_full_graph:\n",
    "            # Use the entire graph for training\n",
    "            subgraph_data = data  # Use the full graph's data\n",
    "        else:\n",
    "            # Get the subgraph centered around the start entity and filtered by relation steps\n",
    "            subgraph_data = get_subgraph_with_relation_steps(start_entity_idx, G, data, relation_steps, hops=3)\n",
    "\n",
    "        # Move the graph data (either full or subgraph) to the correct device (e.g., GPU)\n",
    "        subgraph_data = subgraph_data.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass through the GNN model (on the full graph or subgraph)\n",
    "        out = model(subgraph_data)  # Model predicts scores for all nodes in the (sub)graph\n",
    "\n",
    "        # Pre-initialize labels as zeros (subgraph_data.y) and map global to local indices\n",
    "        subgraph_data.y = torch.zeros(subgraph_data.num_nodes, dtype=torch.long).to(device)\n",
    "        global_to_local_idx = {global_id: local_id for local_id, global_id in enumerate(subgraph_data.global_node_id)}\n",
    "\n",
    "        # Mark the correct answer nodes in the graph as 1\n",
    "        for answer_idx in answer_indices:\n",
    "            # Map global answer_idx to the local subgraph node using the precomputed global_to_local_idx\n",
    "            local_answer_idx = global_to_local_idx.get(answer_idx)\n",
    "            if local_answer_idx is not None:\n",
    "                subgraph_data.y[local_answer_idx] = 1\n",
    "            else:\n",
    "                missing_answer += 1\n",
    "                print(f\"Warning: Answer node {answer_idx} not found in the (sub)graph; counter: {missing_answer}; question_data: {c}\")\n",
    "\n",
    "        # Compute the loss (CrossEntropy between the predicted outputs and actual labels)\n",
    "        loss = criterion(out, subgraph_data.y)\n",
    "        loss.backward()  # Backpropagate the gradients\n",
    "        optimizer.step()  # Update model parameters\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train_gnn(question_data, data):\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    for q in tqdm(question_data, desc=\"Training Progress\"):\n",
    "        start_entity_idx = q['start_entity_idx']\n",
    "        answer_indices = q['answer_indices']\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass through the GNN model\n",
    "        out = model(data)  # out is a prediction for each node\n",
    "\n",
    "        # Create the target labels (1 for answer nodes, 0 for others)\n",
    "        labels = torch.zeros(data.num_nodes, dtype=torch.long).to(device)\n",
    "        for answer_idx in answer_indices:\n",
    "            labels[answer_idx] = 1\n",
    "\n",
    "        # Compute the loss (CrossEntropy between predictions and labels)\n",
    "        loss = criterion(out, labels)\n",
    "        loss.backward()  # Backpropagate\n",
    "        optimizer.step()  # Update model parameters\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (A) Very slow\n",
    "\n",
    "# from tqdm import tqdm  # For progress bars\n",
    "\n",
    "# start_time = time.time()\n",
    "\n",
    "# # Use tqdm to display progress bar\n",
    "# # for epoch in tqdm(range(1), desc=\"Training Progress\"):\n",
    "# for epoch in range(1):\n",
    "#     loss = train_gnn_with_subgraph(question_data, data, G, use_full_graph=False)\n",
    "#     if epoch % 10 == 0:\n",
    "#         print(f'Epoch {epoch}, Loss: {loss}')\n",
    "\n",
    "# end_time = time.time()\n",
    "# elapsed_time = end_time - start_time\n",
    "# print(f\"Time taken: {elapsed_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 114196/114196 [07:02<00:00, 270.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 261.0352136149886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):\n",
    "    loss = train_gnn(question_data, data)\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_answer(model, data, start_entity_name):\n",
    "    # Convert the start entity name to its index in the graph\n",
    "    if start_entity_name not in node_to_index:\n",
    "        print(f\"Entity '{start_entity_name}' not found in the graph.\")\n",
    "        return None\n",
    "\n",
    "    start_entity_idx = node_to_index[start_entity_name]\n",
    "\n",
    "    # Forward pass through the model (entire graph) on the correct device\n",
    "    with torch.no_grad():  # Disable gradient computation for inference\n",
    "        out = model(data)  # Model predicts scores for all nodes (shape: [num_nodes, 2])\n",
    "\n",
    "    # Ensure the output is on the correct device\n",
    "    out = out.to(device)\n",
    "\n",
    "    # Get neighbors of the start entity\n",
    "    neighbors = list(G.neighbors(start_entity_name))\n",
    "    neighbors_idx = [node_to_index[neighbor] for neighbor in neighbors if neighbor in node_to_index]\n",
    "\n",
    "    # Create a mask: 1 for neighbor nodes, 0 otherwise\n",
    "    mask = torch.zeros(out.shape[0], dtype=torch.bool).to(device)  # Ensure the mask is on the same device\n",
    "    if neighbors_idx:  # Check if neighbors exist\n",
    "        mask[neighbors_idx] = 1  # Mark neighbors of the start entity\n",
    "\n",
    "    # Expand the mask to be broadcasted across the second dimension (class dimension)\n",
    "    mask = mask.unsqueeze(1)  # Shape: [num_nodes, 1], which will broadcast to [num_nodes, 2]\n",
    "\n",
    "    # Apply the mask to the output\n",
    "    masked_out = out * mask  # Shape: [num_nodes, 2]\n",
    "\n",
    "    # Apply torch.argmax to find the node with the highest score for class 1 (the \"correct\" class)\n",
    "    predicted_answer_idx = torch.argmax(masked_out[:, 1])  # Pick the 1 class (assuming binary classification)\n",
    "\n",
    "    # Convert the predicted index back to the node name (entity name)\n",
    "    predicted_answer = graph_node_order[predicted_answer_idx.item()]  # Convert tensor to integer index and map to name\n",
    "\n",
    "    return predicted_answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Kismet'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_answer(model, data, 'Kismet') # ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and setup dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "<!-- - pip3 install torch torchvision torchaudio -->\n",
    "- pip install torch-scatter\n",
    "  - https://github.com/rusty1s/pytorch_scatter/issues/424\n",
    "- pip install torch-geometric \n",
    "- pip install pandas\n",
    "- pip install sentence-transformers\n",
    "- pip install ipywidgets\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "import os\n",
    "\n",
    "file_path = os.path.abspath('../data_preparation/functions_modified.py')\n",
    "\n",
    "# Load the module dynamically\n",
    "spec = importlib.util.spec_from_file_location(\"functions\", file_path)\n",
    "functions = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_node_embed = '../Datasets/MetaQA_dataset/processed/node2vec _embeddings/ud_node2vec_embeddings.txt'\n",
    "path_to_idxes = '../Datasets/MetaQA_dataset/processed/idxes.json'\n",
    "path_to_qa = '../Datasets/MetaQA_dataset/vanilla 3-hop/qa_train.txt'\n",
    "data = functions.KGQADataset(path_to_node_embed, path_to_idxes, path_to_qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# data_loader = DataLoader(data, batch_size=16, collate_fn=functions.collate_fn, shuffle=True)\n",
    "# data_loader = DataLoader(data, batch_size=16, collate_fn=functions.collate_fn, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GNNModel(nn.Module):\n",
    "    def __init__(self, in_channels, question_embedding_dim, out_channels):\n",
    "        super(GNNModel, self).__init__()\n",
    "        PROC_QN_EMBED_DIM = 64  # Reduced question embedding dimension (keep it small)\n",
    "        PROC_X_DIM = 64          # Reduced node embedding dimension (keep it small)\n",
    "\n",
    "        # GCN layers for node embeddings\n",
    "        self.conv1 = GCNConv(in_channels, 32)  # First GCN layer\n",
    "        self.conv2 = GCNConv(32, PROC_X_DIM)   # Second GCN layer, reduces node embedding to 4\n",
    "\n",
    "        # Fully connected layer for reducing question embeddings\n",
    "        self.fc0 = nn.Linear(question_embedding_dim, PROC_QN_EMBED_DIM)\n",
    "\n",
    "        # Fully connected layer applied to each node embedding (after concatenating with question embedding)\n",
    "        self.fc1 = nn.Linear(PROC_X_DIM + PROC_QN_EMBED_DIM, 32)  # FCL for each node\n",
    "        self.fc2 = nn.Linear(32, out_channels)  # Final output (binary classification per node)\n",
    "\n",
    "    def forward(self, data, question_embedding):\n",
    "        # Graph propagation through GCN layers\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        # input(f\"x.shape: {x.shape}\")\n",
    "\n",
    "        # Reduce the question embedding\n",
    "        # input(f\"before reduction question_embedding.shape: {question_embedding.shape}\")\n",
    "        question_embedding = F.relu(self.fc0(question_embedding))  # Shape: (batch_size, PROC_QN_EMBED_DIM)\n",
    "        # input(f\"After reduction question_embedding.shape: {question_embedding.shape}\")\n",
    "\n",
    "        # Broadcast question embedding to match each node in the batch\n",
    "        question_embedding_expanded = question_embedding[batch]  # Shape: (num_nodes_total, PROC_QN_EMBED_DIM)\n",
    "        # input(f\"After broacast question_embedding.shape: {question_embedding_expanded.shape}\")\n",
    "\n",
    "        # Concatenate node embeddings with question embeddings\n",
    "        combined = torch.cat([x, question_embedding_expanded], dim=1)  # Shape: (num_nodes_total, PROC_X_DIM + PROC_QN_EMBED_DIM)\n",
    "        # input(f\"combined.shape: {combined.shape}\")\n",
    "\n",
    "        # Apply FCL node-wise (same FCL for each node, which outputs per node predictions)\n",
    "        x = F.relu(self.fc1(combined))  # Shape: (num_nodes_total, 8)\n",
    "        x = self.fc2(x)                 # Shape: (num_nodes_total, out_channels)\n",
    "        # input(f\"output.shape: {x.shape}\")\n",
    "\n",
    "        # Return node-wise predictions (logits for each node)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_data1 = torch.utils.data.Subset(data, list(range(1280)))\n",
    "dataloader_train = DataLoader(sub_data1, batch_size=4, collate_fn=functions.collate_fn, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 320/320 [02:19<00:00,  2.29it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "progress_bar = tqdm(dataloader_train)\n",
    "pos_cum = 0\n",
    "neg_cum = 0\n",
    "neg_pos = []\n",
    "for b in progress_bar:\n",
    "    _, _, labels, _ = b\n",
    "    pos = sum(labels)\n",
    "    neg = len(labels) - pos\n",
    "    pos_cum += pos\n",
    "    neg_cum += neg\n",
    "    neg_pos.append(neg/pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([16301]) tensor([14497185]) tensor([889.3433])\n",
      "tensor([1485.6534], device='cuda:0')\n",
      "tensor([9080.1670], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(pos_cum, neg_cum, neg_cum/pos_cum)\n",
    "print(torch.tensor([sum(neg_pos)/len(neg_pos)],device=device))\n",
    "print(torch.tensor([max(neg_pos)],device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████| 320/320 [01:54<00:00,  2.79it/s, loss=5.75e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Total Loss: 5752.3131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import torch_scatter\n",
    "\n",
    "# Define the device (use GPU if available)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initialize the GNN model\n",
    "in_channels = 64  # Node embedding dimension (e.g., node2vec embeddings)\n",
    "question_embedding_dim = 384  # Assuming 32-dimensional question embeddings\n",
    "out_channels = 1  # Binary classification (answer or not)\n",
    "model = GNNModel(in_channels, question_embedding_dim, out_channels).to(device)\n",
    "\n",
    "# Calculate the number of positive and negative samples for class weighting\n",
    "num_positive = pos_cum  # Set the number of positive examples in your dataset\n",
    "num_negative = neg_cum  # Set the number of negative examples in your dataset\n",
    "factor = 10^2\n",
    "# Set the positive weight (to balance the class distribution)\n",
    "# The higher the imbalance, the larger this value will be\n",
    "# pos_weight = torch.tensor([num_negative / num_positive], device=device)\n",
    "pos_weight = torch.tensor([factor*sum(neg_pos)/len(neg_pos)],device=device)\n",
    "\n",
    "# Set up optimizer and weighted loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight, reduction='none')\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    total_loss = 0\n",
    "\n",
    "    # Add tqdm for batches within the epoch\n",
    "    progress_bar = tqdm(dataloader_train, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "    for batch in progress_bar:\n",
    "        subgraph_data, question_embeddings, labels, _ = batch\n",
    "\n",
    "        # Move data to the correct device\n",
    "        subgraph_data = subgraph_data.to(device)\n",
    "        question_embeddings = question_embeddings.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        out = model(subgraph_data, question_embeddings)\n",
    "\n",
    "        # Compute the number of nodes per subgraph\n",
    "        num_subgraphs = len(subgraph_data.batch.unique())\n",
    "        nodes_per_subgraph = subgraph_data.batch.bincount(minlength=num_subgraphs).float()  # Shape: [num_subgraphs]\n",
    "\n",
    "        # Compute weighted loss for each node\n",
    "        loss = criterion(out, labels.float())\n",
    "\n",
    "        # Sum the losses for all nodes in each subgraph\n",
    "        loss_per_subgraph = torch_scatter.scatter_add(loss, subgraph_data.batch, dim=0)\n",
    "\n",
    "        # Normalize the loss per subgraph by the number of nodes in each subgraph\n",
    "        normalized_loss_per_subgraph = loss_per_subgraph / nodes_per_subgraph\n",
    "\n",
    "        # Take the mean of normalized losses for the batch\n",
    "        batch_loss = normalized_loss_per_subgraph.mean()\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss.backward()  # Backpropagate\n",
    "        optimizer.step()  # Optimization step\n",
    "\n",
    "        total_loss += batch_loss.detach().item()\n",
    "\n",
    "        # Update tqdm with the current loss\n",
    "        progress_bar.set_postfix(loss=total_loss)\n",
    "\n",
    "    # Optionally clear CUDA memory cache after each epoch\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Print total loss per epoch\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Total Loss: {total_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 320/320 [02:30<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.99730150\n",
      "Average Precision: 0.00000000\n",
      "Average Recall: 0.00000000\n",
      "Average F1-Score: 0.00000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch_scatter\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "batch_accuracies = []  # List to store accuracy of each question/subgraph\n",
    "batch_precisions = []  # List to store precision of each subgraph\n",
    "batch_recalls = []  # List to store recall of each subgraph\n",
    "batch_f1s = []  # List to store F1-score of each subgraph\n",
    "pred_list = []\n",
    "\n",
    "# Add tqdm for batches within the epoch\n",
    "progress_bar = tqdm(dataloader_train, desc=\"Training\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in progress_bar:\n",
    "        subgraph_data, question_embeddings, labels, _ = batch  # Assuming labels are in the batch\n",
    "\n",
    "        # Move data to the device\n",
    "        subgraph_data = subgraph_data.to(device)\n",
    "        question_embeddings = question_embeddings.to(device)\n",
    "        labels = labels.to(device)  # Move the ground truth labels to the device\n",
    "\n",
    "        # Forward pass\n",
    "        out = model(subgraph_data, question_embeddings)\n",
    "\n",
    "        # Detach the predicted labels\n",
    "        predicted = torch.argmax(out, dim=1).detach()  # Detach to avoid gradient tracking\n",
    "\n",
    "        # Keep everything on the same device (GPU)\n",
    "        predicted_flat = predicted.view(-1)\n",
    "        labels_flat = labels.view(-1)\n",
    "        pred_list.append(sum(predicted_flat))\n",
    "\n",
    "        # Compute accuracy for all nodes (1 for correct predictions, 0 for incorrect)\n",
    "        correct_predictions = (predicted_flat == labels_flat).int()\n",
    "\n",
    "        # Use subgraph_data.batch to group predictions by subgraph (make sure it's on the same device)\n",
    "        num_subgraphs = len(subgraph_data.batch.unique())\n",
    "        nodes_per_subgraph = subgraph_data.batch.bincount(minlength=num_subgraphs)  # Count nodes in each subgraph\n",
    "\n",
    "        # Sum correct predictions per subgraph\n",
    "        correct_per_subgraph = torch_scatter.scatter_add(correct_predictions, subgraph_data.batch, dim=0)\n",
    "\n",
    "        # Calculate accuracy per subgraph\n",
    "        subgraph_accuracies = correct_per_subgraph / nodes_per_subgraph\n",
    "\n",
    "        # Append accuracies for each subgraph in the batch\n",
    "        batch_accuracies.extend(subgraph_accuracies.cpu().tolist())  # Move the results to CPU\n",
    "\n",
    "        # Compute precision, recall, and F1-score per subgraph\n",
    "        for i in range(num_subgraphs):\n",
    "            node_mask = (subgraph_data.batch == i)  # Get the mask for the current subgraph\n",
    "\n",
    "            # Get the true labels and predictions for this subgraph\n",
    "            labels_subgraph = labels_flat[node_mask].cpu().numpy()  # Convert to numpy for sklearn\n",
    "            predicted_subgraph = predicted_flat[node_mask].cpu().numpy()\n",
    "\n",
    "            if len(set(labels_subgraph)) > 1:  # Avoid cases where only one class exists\n",
    "                precision = precision_score(labels_subgraph, predicted_subgraph, average='binary', zero_division=0)\n",
    "                recall = recall_score(labels_subgraph, predicted_subgraph, average='binary', zero_division=0)\n",
    "                f1 = f1_score(labels_subgraph, predicted_subgraph, average='binary', zero_division=0)\n",
    "            else:\n",
    "                # Handle the case when all labels are the same (sklearn can raise a warning or return 0)\n",
    "                precision, recall, f1 = 0.0, 0.0, 0.0\n",
    "\n",
    "            # Store the precision, recall, and F1-score\n",
    "            batch_precisions.append(precision)\n",
    "            batch_recalls.append(recall)\n",
    "            batch_f1s.append(f1)\n",
    "\n",
    "# Compute the average accuracy, precision, recall, and F1-score over all subgraphs in the batch\n",
    "average_accuracy = sum(batch_accuracies) / len(batch_accuracies)\n",
    "average_precision = sum(batch_precisions) / len(batch_precisions)\n",
    "average_recall = sum(batch_recalls) / len(batch_recalls)\n",
    "average_f1 = sum(batch_f1s) / len(batch_f1s)\n",
    "\n",
    "print(f\"Average Accuracy: {average_accuracy:.8f}\")\n",
    "print(f\"Average Precision: {average_precision:.8f}\")\n",
    "print(f\"Average Recall: {average_recall:.8f}\")\n",
    "print(f\"Average F1-Score: {average_f1:.8f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 320/320 [03:23<00:00,  1.57it/s]\n"
     ]
    }
   ],
   "source": [
    "# pred_list\n",
    "p = 0\n",
    "pb = tqdm(pred_list)\n",
    "for l in pb:\n",
    "    p += sum(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0, device='cuda:0')"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_data2 = torch.utils.data.Subset(data, list(range(1281, 1600)))\n",
    "dataloader_val = DataLoader(sub_data2, batch_size=16, collate_fn=functions.collate_fn, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 20/20 [00:36<00:00,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.99727723\n",
      "Average Precision: 0.00000000\n",
      "Average Recall: 0.00000000\n",
      "Average F1-Score: 0.00000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch_scatter\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "batch_accuracies = []  # List to store accuracy of each question/subgraph\n",
    "batch_precisions = []  # List to store precision of each subgraph\n",
    "batch_recalls = []  # List to store recall of each subgraph\n",
    "batch_f1s = []  # List to store F1-score of each subgraph\n",
    "\n",
    "# Add tqdm for batches within the epoch\n",
    "progress_bar = tqdm(dataloader_val, desc=\"Validation\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in progress_bar:\n",
    "        subgraph_data, question_embeddings, labels, _ = batch  # Assuming labels are in the batch\n",
    "\n",
    "        # Move data to the device\n",
    "        subgraph_data = subgraph_data.to(device)\n",
    "        question_embeddings = question_embeddings.to(device)\n",
    "        labels = labels.to(device)  # Move the ground truth labels to the device\n",
    "\n",
    "        # Forward pass\n",
    "        out = model(subgraph_data, question_embeddings)\n",
    "\n",
    "        # Detach the predicted labels\n",
    "        predicted = torch.argmax(out, dim=1).detach()  # Detach to avoid gradient tracking\n",
    "\n",
    "        # Keep everything on the same device (GPU)\n",
    "        predicted_flat = predicted.view(-1)\n",
    "        labels_flat = labels.view(-1)\n",
    "\n",
    "        # Compute accuracy for all nodes (1 for correct predictions, 0 for incorrect)\n",
    "        correct_predictions = (predicted_flat == labels_flat).int()\n",
    "\n",
    "        # Use subgraph_data.batch to group predictions by subgraph (make sure it's on the same device)\n",
    "        num_subgraphs = len(subgraph_data.batch.unique())\n",
    "        nodes_per_subgraph = subgraph_data.batch.bincount(minlength=num_subgraphs)  # Count nodes in each subgraph\n",
    "\n",
    "        # Sum correct predictions per subgraph\n",
    "        correct_per_subgraph = torch_scatter.scatter_add(correct_predictions, subgraph_data.batch, dim=0)\n",
    "\n",
    "        # Calculate accuracy per subgraph\n",
    "        subgraph_accuracies = correct_per_subgraph / nodes_per_subgraph\n",
    "\n",
    "        # Append accuracies for each subgraph in the batch\n",
    "        batch_accuracies.extend(subgraph_accuracies.cpu().tolist())  # Move the results to CPU\n",
    "\n",
    "        # Compute precision, recall, and F1-score per subgraph\n",
    "        for i in range(num_subgraphs):\n",
    "            node_mask = (subgraph_data.batch == i)  # Get the mask for the current subgraph\n",
    "\n",
    "            # Get the true labels and predictions for this subgraph\n",
    "            labels_subgraph = labels_flat[node_mask].cpu().numpy()  # Convert to numpy for sklearn\n",
    "            predicted_subgraph = predicted_flat[node_mask].cpu().numpy()\n",
    "\n",
    "            if len(set(labels_subgraph)) > 1:  # Avoid cases where only one class exists\n",
    "                precision = precision_score(labels_subgraph, predicted_subgraph, average='binary', zero_division=0)\n",
    "                recall = recall_score(labels_subgraph, predicted_subgraph, average='binary', zero_division=0)\n",
    "                f1 = f1_score(labels_subgraph, predicted_subgraph, average='binary', zero_division=0)\n",
    "            else:\n",
    "                # Handle the case when all labels are the same (sklearn can raise a warning or return 0)\n",
    "                precision, recall, f1 = 0.0, 0.0, 0.0\n",
    "\n",
    "            # Store the precision, recall, and F1-score\n",
    "            batch_precisions.append(precision)\n",
    "            batch_recalls.append(recall)\n",
    "            batch_f1s.append(f1)\n",
    "\n",
    "# Compute the average accuracy, precision, recall, and F1-score over all subgraphs in the batch\n",
    "average_accuracy = sum(batch_accuracies) / len(batch_accuracies)\n",
    "average_precision = sum(batch_precisions) / len(batch_precisions)\n",
    "average_recall = sum(batch_recalls) / len(batch_recalls)\n",
    "average_f1 = sum(batch_f1s) / len(batch_f1s)\n",
    "\n",
    "print(f\"Average Accuracy: {average_accuracy:.8f}\")\n",
    "print(f\"Average Precision: {average_precision:.8f}\")\n",
    "print(f\"Average Recall: {average_recall:.8f}\")\n",
    "print(f\"Average F1-Score: {average_f1:.8f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = functions.KGQADataset(path_to_node_embed, path_to_idxes, '../Datasets/MetaQA_dataset/vanilla 3-hop/qa_test.txt')\n",
    "sub_data3 = torch.utils.data.Subset(test, list(range(1601, 1920)))\n",
    "dataloader_test = DataLoader(sub_data3, batch_size=16, collate_fn=functions.collate_fn, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_scatter\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "batch_accuracies = []  # List to store accuracy of each question/subgraph\n",
    "batch_precisions = []  # List to store precision of each subgraph\n",
    "batch_recalls = []  # List to store recall of each subgraph\n",
    "batch_f1s = []  # List to store F1-score of each subgraph\n",
    "\n",
    "# Add tqdm for batches within the epoch\n",
    "progress_bar = tqdm(dataloader_test, desc=\"Testing\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in progress_bar:\n",
    "        subgraph_data, question_embeddings, labels, _ = batch  # Assuming labels are in the batch\n",
    "\n",
    "        # Move data to the device\n",
    "        subgraph_data = subgraph_data.to(device)\n",
    "        question_embeddings = question_embeddings.to(device)\n",
    "        labels = labels.to(device)  # Move the ground truth labels to the device\n",
    "\n",
    "        # Forward pass\n",
    "        out = model(subgraph_data, question_embeddings)\n",
    "\n",
    "        # Detach the predicted labels\n",
    "        predicted = torch.argmax(out, dim=1).detach()  # Detach to avoid gradient tracking\n",
    "\n",
    "        # Keep everything on the same device (GPU)\n",
    "        predicted_flat = predicted.view(-1)\n",
    "        labels_flat = labels.view(-1)\n",
    "\n",
    "        # Compute accuracy for all nodes (1 for correct predictions, 0 for incorrect)\n",
    "        correct_predictions = (predicted_flat == labels_flat).int()\n",
    "\n",
    "        # Use subgraph_data.batch to group predictions by subgraph (make sure it's on the same device)\n",
    "        num_subgraphs = len(subgraph_data.batch.unique())\n",
    "        nodes_per_subgraph = subgraph_data.batch.bincount(minlength=num_subgraphs)  # Count nodes in each subgraph\n",
    "\n",
    "        # Sum correct predictions per subgraph\n",
    "        correct_per_subgraph = torch_scatter.scatter_add(correct_predictions, subgraph_data.batch, dim=0)\n",
    "\n",
    "        # Calculate accuracy per subgraph\n",
    "        subgraph_accuracies = correct_per_subgraph / nodes_per_subgraph\n",
    "\n",
    "        # Append accuracies for each subgraph in the batch\n",
    "        batch_accuracies.extend(subgraph_accuracies.cpu().tolist())  # Move the results to CPU\n",
    "\n",
    "        # Compute precision, recall, and F1-score per subgraph\n",
    "        for i in range(num_subgraphs):\n",
    "            node_mask = (subgraph_data.batch == i)  # Get the mask for the current subgraph\n",
    "\n",
    "            # Get the true labels and predictions for this subgraph\n",
    "            labels_subgraph = labels_flat[node_mask].cpu().numpy()  # Convert to numpy for sklearn\n",
    "            predicted_subgraph = predicted_flat[node_mask].cpu().numpy()\n",
    "\n",
    "            if len(set(labels_subgraph)) > 1:  # Avoid cases where only one class exists\n",
    "                precision = precision_score(labels_subgraph, predicted_subgraph, average='binary', zero_division=0)\n",
    "                recall = recall_score(labels_subgraph, predicted_subgraph, average='binary', zero_division=0)\n",
    "                f1 = f1_score(labels_subgraph, predicted_subgraph, average='binary', zero_division=0)\n",
    "            else:\n",
    "                # Handle the case when all labels are the same (sklearn can raise a warning or return 0)\n",
    "                precision, recall, f1 = 0.0, 0.0, 0.0\n",
    "\n",
    "            # Store the precision, recall, and F1-score\n",
    "            batch_precisions.append(precision)\n",
    "            batch_recalls.append(recall)\n",
    "            batch_f1s.append(f1)\n",
    "\n",
    "# Compute the average accuracy, precision, recall, and F1-score over all subgraphs in the batch\n",
    "average_accuracy = sum(batch_accuracies) / len(batch_accuracies)\n",
    "average_precision = sum(batch_precisions) / len(batch_precisions)\n",
    "average_recall = sum(batch_recalls) / len(batch_recalls)\n",
    "average_f1 = sum(batch_f1s) / len(batch_f1s)\n",
    "\n",
    "print(f\"Average Accuracy: {average_accuracy:.8f}\")\n",
    "print(f\"Average Precision: {average_precision:.8f}\")\n",
    "print(f\"Average Recall: {average_recall:.8f}\")\n",
    "print(f\"Average F1-Score: {average_f1:.8f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS5284_Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
