{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16b3a4c8-d5fe-4d1b-b223-3757949fbc1c",
   "metadata": {},
   "source": [
    "### Extract target answer type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ef7be9f-ff63-4360-827d-b27514d29042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from langchain.prompts import PromptTemplate\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b00634c-4f5d-4291-846d-b5ddcea144b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examples extracted from train\n",
    "class baseline_LLM:\n",
    "    def __init__(self, model_path):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(model_path,\n",
    "                                                          device_map=\"auto\",\n",
    "                                                          torch_dtype=torch.bfloat16)\n",
    "        self.template =\"\"\"\n",
    "You are tasked to extract the answer entity type corresponding to a question.\n",
    "\n",
    "Here are some examples:\n",
    "who wrote films that share actors with the film [Anastasia] => writer\n",
    "which person directed the films acted by the actors in [Jawbreaker] => director\n",
    "what languages are the films that share directors with [The Age of Innocence] in => language\n",
    "who starred in the films whose directors also directed [The Decline of the American Empire] => actor\n",
    "when did the movies release whose actors also appear in the movie [Little Big Man] => year\n",
    "which person wrote the movies directed by the director of [Incognito] => writer\n",
    "who are the directors of the movies written by the writer of [The Green Mile] => director\n",
    "what types are the films directed by the director of [The Conspirator] => genre\n",
    "what genres are the movies written by [The Beast] writers => genre\n",
    "who acted in the films directed by the director of [Terms of Endearment] => actor\n",
    "the films that share actors with the film [Dil Chahta Hai] were released in which years => year\n",
    "the movies written by the screenwriter of [The Science of Sleep] starred who => actor\n",
    "who directed the movies written by the writer of [A Sunday in the Country] => director\n",
    "the films written by the screenwriter of [Dracula 2000] were directed by who => director\n",
    "who is listed as director of the movies starred by [Our Modern Maidens] actors => director\n",
    "when did the movies written by [Europa] writers release => year\n",
    "what types are the movies written by the writer of [The Green Hornet] => genre\n",
    "\n",
    "No explanation required. Output one of: 'actor', 'director', 'genre', 'language', 'writer', 'year'.\n",
    "\n",
    "{question} =>\n",
    "\"\"\"\n",
    "        self.prompt_template = PromptTemplate.from_template(self.template)\n",
    "\n",
    "    def predict(self, question):\n",
    "        formatted_prompt = self.prompt_template.format(question = question)\n",
    "\n",
    "        chat = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": formatted_prompt},\n",
    "        ]\n",
    "\n",
    "        tokenized_chat = self.tokenizer.apply_chat_template(chat, tokenize=True, add_generation_prompt=True, return_tensors=\"pt\").to(device)\n",
    "\n",
    "        outputs = self.model.generate(tokenized_chat, max_new_tokens=100, pad_token_id=self.tokenizer.eos_token_id).cpu()\n",
    "        tokenized_chat = tokenized_chat.cpu() ###\n",
    "        del tokenized_chat ###\n",
    "\n",
    "        return self.tokenizer.decode(outputs[0]).split(\"<|end_header_id|>\")[-1].strip().split(\"<|eot_id|>\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6839c818-b65e-4018-a593-f20d549893ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1d9ce6cd1ff41219b70434c1a057c4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load model\n",
    "llm = baseline_LLM(\"/scratch/users/nus/e1329380/models/models--meta-llama--Llama-3.1-8B-Instruct/snapshots/0e9e39f249a16976918f6564b8830bc894c89659/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b129e83-d944-43ab-93a6-2c85c1363010",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'year'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing\n",
    "qn = \"the films that share actors with the film [Dil Chahta Hai] were released in which years\"\n",
    "llm.predict(qn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e39eaeda-01f9-492a-a38b-40e94f21fa1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 5000/5000 [06:17<00:00, 13.25it/s]\n"
     ]
    }
   ],
   "source": [
    "# iterate through train (first 5000)\n",
    "df = pd.read_csv('../Datasets/MetaQA_dataset/vanilla 3-hop/qa_train.txt', sep='\\t', header=None, names=['question', 'answer'])\n",
    "with open('../Datasets/MetaQA_dataset/processed/train_ans_type.txt', 'w') as f:\n",
    "    for idx in tqdm(range(5000)):\n",
    "        f.write(llm.predict(df.question.iloc[idx]))\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a03a490-4cb2-4060-9540-4d26137e2cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check against groundtruth\n",
    "gt_types = []\n",
    "with open('../Datasets/MetaQA_dataset/vanilla 3-hop/qa_train_qtype.txt') as f:\n",
    "    for line in f:\n",
    "        gt_types.append(line.strip().split(\"_\")[-1])\n",
    "gt_types = gt_types[:5000]\n",
    "\n",
    "pred_types = []\n",
    "with open('../Datasets/MetaQA_dataset/processed/train_ans_type.txt') as f:\n",
    "    for line in f:\n",
    "        if line:\n",
    "            pred_types.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8bc406e8-5b09-42fa-b97f-52018e96e753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "sum([1 for (i, j) in zip(gt_types, pred_types) if i!=j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5128770a-4a90-42b3-b32b-58cbbcb22865",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1000/1000 [01:15<00:00, 13.26it/s]\n"
     ]
    }
   ],
   "source": [
    "# iterate through train (first 1000)\n",
    "df = pd.read_csv('../Datasets/MetaQA_dataset/vanilla 3-hop/qa_dev.txt', sep='\\t', header=None, names=['question', 'answer'])\n",
    "with open('../Datasets/MetaQA_dataset/processed/dev_ans_type.txt', 'w') as f:\n",
    "    for idx in tqdm(range(1000)):\n",
    "        f.write(llm.predict(df.question.iloc[idx]))\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e378b0c-2505-41bb-9f54-4a5f05bbc832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check against groundtruth\n",
    "gt_types = []\n",
    "with open('../Datasets/MetaQA_dataset/vanilla 3-hop/qa_dev_qtype.txt') as f:\n",
    "    for line in f:\n",
    "        gt_types.append(line.strip().split(\"_\")[-1])\n",
    "\n",
    "pred_types = []\n",
    "with open('../Datasets/MetaQA_dataset/processed/dev_ans_type.txt') as f:\n",
    "    for line in f:\n",
    "        if line:\n",
    "            pred_types.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b79fb9e-9755-44b2-b765-5ead406d21ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "sum([1 for (i, j) in zip(gt_types, pred_types) if i!=j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d975664-3db0-465f-bbd4-cd1e8d8a6d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1000/1000 [01:15<00:00, 13.25it/s]\n"
     ]
    }
   ],
   "source": [
    "# iterate through train (first 1000)\n",
    "df = pd.read_csv('../Datasets/MetaQA_dataset/vanilla 3-hop/qa_test.txt', sep='\\t', header=None, names=['question', 'answer'])\n",
    "with open('../Datasets/MetaQA_dataset/processed/test_ans_type.txt', 'w') as f:\n",
    "    for idx in tqdm(range(1000)):\n",
    "        f.write(llm.predict(df.question.iloc[idx]))\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "178b8a15-2bfb-461f-8a14-d6b0a43461b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check against groundtruth\n",
    "gt_types = []\n",
    "with open('../Datasets/MetaQA_dataset/vanilla 3-hop/qa_test_qtype.txt') as f:\n",
    "    for line in f:\n",
    "        gt_types.append(line.strip().split(\"_\")[-1])\n",
    "\n",
    "pred_types = []\n",
    "with open('../Datasets/MetaQA_dataset/processed/test_ans_type.txt') as f:\n",
    "    for line in f:\n",
    "        if line:\n",
    "            pred_types.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "225c5887-f139-4fbf-92e5-7cd7b6e8c81c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "sum([1 for (i, j) in zip(gt_types, pred_types) if i!=j])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46952f5a-1ac0-4402-b412-398d28456dea",
   "metadata": {},
   "source": [
    "### Extract node entity type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2430546f-e111-4505-b674-ab79a43a7d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions_modified import *\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "path_to_node_embed = '../Datasets/MetaQA_dataset/processed/node2vec _embeddings/ud_node2vec_embeddings.txt'\n",
    "path_to_idxes = '../Datasets/MetaQA_dataset/processed/idxes.json'\n",
    "path_to_qa = '../Datasets/MetaQA_dataset/vanilla 3-hop/qa_train.txt'\n",
    "path_to_ans_types = '../Datasets/MetaQA_dataset/processed/train_ans_type.txt'\n",
    "data = KGQADataset(path_to_node_embed, path_to_idxes, path_to_qa, path_to_ans_types, train = True)\n",
    "\n",
    "dataloader = DataLoader(data, batch_size=16, collate_fn=collate_fn, shuffle=True)\n",
    "\n",
    "for batched_subgraphs, question_embeddings, stacked_labels, node_maps, labels, answer_types in dataloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "11ed2000-ed4e-478e-8f25-5e9eeccc4f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 7\n",
    "sum(np.array(labels[i])[np.where(np.array(batched_subgraphs[i].node_types) == answer_types[i])[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b9c2eb7e-5891-49d9-aed2-54cdacf82e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3d305419-5af1-4245-8a36-7902f5166502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total nodes to calculate loss on or evaluate metric on\n",
    "len(np.array(labels[i])[np.where(np.array(batched_subgraphs[i].node_types) == answer_types[i])[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f50d054e-14e4-4b2f-b23c-7c171834ced4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'genre'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_types[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "810a44ac-b814-4b6d-8253-010be96d01c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(batched_subgraphs.node_types)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
